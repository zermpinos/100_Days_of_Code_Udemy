{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg7IDCTd-d2h"
      },
      "source": [
        "###  Import Statements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3iYmJ3Fb-d2i"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from scipy.stats import skew"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YexUjiVdC0Oe"
      },
      "source": [
        "### Notebook Presentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "AUvdOhPIC4Me"
      },
      "outputs": [],
      "source": [
        "pd.options.display.float_format = '{:,.2f}'.format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRlvO4zw-d2l"
      },
      "source": [
        "# Load the Data\n",
        "\n",
        "The first column in the .csv file just has the row numbers, so it will be used as the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GlG_B81bYakP"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('boston.csv', index_col=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKyJsSdEChd-"
      },
      "source": [
        "### Understand the Boston House Price Dataset\n",
        "\n",
        "---------------------------\n",
        "\n",
        "**Characteristics:**  \n",
        "\n",
        "    :Number of Instances: 506\n",
        "\n",
        "    :Number of Attributes: 13 numeric/categorical predictive. The Median Value (attribute 14) is the target.\n",
        "\n",
        "    :Attribute Information (in order):\n",
        "        1. CRIM     per capita crime rate by town\n",
        "        2. ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
        "        3. INDUS    proportion of non-retail business acres per town\n",
        "        4. CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
        "        5. NOX      nitric oxides concentration (parts per 10 million)\n",
        "        6. RM       average number of rooms per dwelling\n",
        "        7. AGE      proportion of owner-occupied units built prior to 1940\n",
        "        8. DIS      weighted distances to five Boston employment centres\n",
        "        9. RAD      index of accessibility to radial highways\n",
        "        10. TAX      full-value property-tax rate per $10,000\n",
        "        11. PTRATIO  pupil-teacher ratio by town\n",
        "        12. B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
        "        13. LSTAT    % lower status of the population\n",
        "        14. PRICE     Median value of owner-occupied homes in $1000's\n",
        "        \n",
        "    :Missing Attribute Values: None\n",
        "\n",
        "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
        "\n",
        "This is a copy of [UCI ML housing dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/housing/). This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University. You can find the [original research paper here](https://deepblue.lib.umich.edu/bitstream/handle/2027.42/22636/0000186.pdf?sequence=1&isAllowed=y).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DTICpcuYD6BP"
      },
      "source": [
        "# Preliminary Data Exploration ðŸ”Ž"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "whPNpmlF86sh"
      },
      "outputs": [],
      "source": [
        "# Check the shape of the data\n",
        "print(f'Shape of data: {data.shape}')\n",
        "\n",
        "# Check column names\n",
        "print(f'Column names: {data.columns}')\n",
        "\n",
        "# Display the first few rows of the data\n",
        "print(\"First few rows of the data:\")\n",
        "print(data.head())\n",
        "\n",
        "# Display the last few rows of the data\n",
        "print(\"Last few rows of the data:\")\n",
        "print(data.tail())\n",
        "\n",
        "# Check the number of rows in each column\n",
        "print(\"Number of rows in each column:\")\n",
        "print(data.count())\n",
        "\n",
        "# Check for missing values and duplicates\n",
        "print(\"Data information:\")\n",
        "print(data.info())\n",
        "print(f'Any NaN values? {data.isna().values.any()}')\n",
        "print(f'Number of duplicates: {data.duplicated().sum()}')\n",
        "\n",
        "# Check the statistical summary of the numerical columns\n",
        "print(\"Statistical summary of numerical columns:\")\n",
        "print(data.describe())\n",
        "\n",
        "# Visualize missing data\n",
        "import missingno as msno\n",
        "print(\"Nullity matrix:\")\n",
        "msno.matrix(data)\n",
        "\n",
        "# Check data types\n",
        "print(\"Data types:\")\n",
        "print(data.dtypes)\n",
        "\n",
        "# Check unique values for categorical variables\n",
        "for col in data.columns:\n",
        "    if data[col].dtype == 'object':\n",
        "        print(f'{col}: {data[col].unique()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZvNWb0EGsuP"
      },
      "source": [
        "## Descriptive Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmf-vAdK8_he"
      },
      "outputs": [],
      "source": [
        "# Descriptive statistics\n",
        "print(data.describe())\n",
        "\n",
        "# Calculate average students per teacher\n",
        "average_students_per_teacher = data['PTRATIO'].mean()\n",
        "print(f\"Average students per teacher: {average_students_per_teacher:.2f}\")\n",
        "\n",
        "# Calculate average home price\n",
        "average_price = data['PRICE'].mean()\n",
        "print(f\"Average home price: {average_price:.2f}\")\n",
        "\n",
        "# Minimum and maximum values of 'CHAS'\n",
        "min_chas = data['CHAS'].min()\n",
        "max_chas = data['CHAS'].max()\n",
        "print(f\"Minimum CHAS value: {min_chas}\")\n",
        "print(f\"Maximum CHAS value: {max_chas}\")\n",
        "\n",
        "# Count the number of tracts that bound the Charles River and those that don't\n",
        "print(data['CHAS'].value_counts())\n",
        "\n",
        "# Minimum and maximum number of rooms per dwelling\n",
        "min_rooms = data['RM'].min()\n",
        "max_rooms = data['RM'].max()\n",
        "print(f\"Minimum number of rooms per dwelling: {min_rooms:.2f}\")\n",
        "print(f\"Maximum number of rooms per dwelling: {max_rooms:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "v5U4hAo_-d3D"
      },
      "source": [
        "## Visualise the Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "# Home Prices\n",
        "sns.displot(data['PRICE'], bins=50, kde=True, color='#2196f3')\n",
        "plt.title(f'1970s Home Values in Boston. Average: ${(1000*data.PRICE.mean()):.6}')\n",
        "plt.xlabel('Price in 000s')\n",
        "plt.ylabel('Nr. of Homes')\n",
        "plt.show()\n",
        "\n",
        "# Distance to Employment\n",
        "sns.displot(data.DIS, bins=50, kde=True, color='#2196f3')\n",
        "plt.title(f'Distance to Employment Centres. Average: {(data.DIS.mean()):.2}')\n",
        "plt.xlabel('Weighted Distance to 5 Boston Employment Centres')\n",
        "plt.ylabel('Nr. of Homes')\n",
        "plt.show()\n",
        "\n",
        "# Number of Rooms\n",
        "sns.displot(data.RM, kde=True, color='#2196f3')\n",
        "plt.title(f'Distribution of Rooms in Boston. Average: {data.RM.mean():.2}')\n",
        "plt.xlabel('Average Number of Rooms')\n",
        "plt.ylabel('Nr. of Homes')\n",
        "plt.show()\n",
        "\n",
        "# Access to Highways\n",
        "sns.displot(data['RAD'], bins=24, kde=True, color='#2196f3')\n",
        "plt.xlabel('Accessibility to Highways')\n",
        "plt.ylabel('Nr. of Houses')\n",
        "plt.show()\n",
        "\n",
        "# Next to the River\n",
        "river_access = data['CHAS'].value_counts()\n",
        "bar = px.bar(x=['No', 'Yes'], y=river_access.values, color=river_access.values, color_continuous_scale=px.colors.sequential.haline, title='Next to Charles River?')\n",
        "bar.update_layout(xaxis_title='Property Located Next to the River?', yaxis_title='Number of Homes', coloraxis_showscale=False)\n",
        "bar.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_M1pqzVUas7"
      },
      "source": [
        "# Understand the Relationships in the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbMSfXfOqA5R"
      },
      "source": [
        "### Run a Pair Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set the figure size\n",
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "# Pair Plot\n",
        "sns.pairplot(data, corner=True)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Distance from Employment vs. Pollution\n",
        "with sns.axes_style('darkgrid'):\n",
        "    sns.jointplot(x=data['DIS'], y=data['NOX'], height=8, kind='scatter', color='deeppink', joint_kws={'alpha': 0.5})\n",
        "    plt.title('Distance from Employment vs. Pollution')\n",
        "    plt.xlabel('Distance from Employment')\n",
        "    plt.ylabel('Nitric Oxide Pollution')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Proportion of Non-Retail Industry vs. Pollution\n",
        "with sns.axes_style('darkgrid'):\n",
        "    sns.jointplot(x=data['INDUS'], y=data['NOX'], height=7, color='darkgreen', joint_kws={'alpha': 0.5})\n",
        "    plt.title('Proportion of Non-Retail Industry vs. Pollution')\n",
        "    plt.xlabel('Proportion of Non-Retail Industry')\n",
        "    plt.ylabel('Nitric Oxide Pollution')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# % of Lower Income Population vs Average Number of Rooms\n",
        "with sns.axes_style('darkgrid'):\n",
        "    sns.jointplot(x=data['LSTAT'], y=data['RM'], height=7, color='orange', joint_kws={'alpha': 0.5})\n",
        "    plt.title('% of Lower Income Population vs Average Number of Rooms')\n",
        "    plt.xlabel('% of Lower Income Population')\n",
        "    plt.ylabel('Average Number of Rooms')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# % of Lower Income Population vs Home Price\n",
        "with sns.axes_style('darkgrid'):\n",
        "    sns.jointplot(x=data['LSTAT'], y=data['PRICE'], height=7, color='crimson', joint_kws={'alpha': 0.5})\n",
        "    plt.title('% of Lower Income Population vs Home Price')\n",
        "    plt.xlabel('% of Lower Income Population')\n",
        "    plt.ylabel('Home Price')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Number of Rooms vs Home Value\n",
        "with sns.axes_style('darkgrid'):\n",
        "    sns.jointplot(x=data['RM'], y=data['PRICE'], height=7, color='darkblue', joint_kws={'alpha': 0.5})\n",
        "    plt.title('Number of Rooms vs Home Value')\n",
        "    plt.xlabel('Number of Rooms')\n",
        "    plt.ylabel('Home Value')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "QBQWGOph-d36"
      },
      "source": [
        "# Split Training & Test Dataset\n",
        "\n",
        "We *can't* use all 506 entries in our dataset to train our model. The reason is that we want to evaluate our model on data that it hasn't seen yet (i.e., out-of-sample data). That way we can get a better idea of its performance in the real world."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split Training & Test Dataset\n",
        "features = data.drop('PRICE', axis=1)\n",
        "target = data['PRICE']\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=10)\n",
        "\n",
        "# Print the percentage of training and test data\n",
        "train_pct = 100 * len(x_train) / len(features)\n",
        "test_pct = 100 * len(x_test) / len(features)\n",
        "\n",
        "print(f'Training data: {train_pct:.2f}%')\n",
        "print(f'Test data: {test_pct:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "durruvRj-d3-"
      },
      "source": [
        "# Multivariable Regression\n",
        "\n",
        "In a previous lesson, we had a linear model with only a single feature (our movie budgets). This time we have a total of 13 features. Therefore, our Linear Regression model will have the following form:\n",
        "\n",
        "$$ PR \\hat ICE = \\theta _0 + \\theta _1 RM + \\theta _2 NOX + \\theta _3 DIS + \\theta _4 CHAS ... + \\theta _{13} LSTAT$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the regression on the training dataset\n",
        "regr = LinearRegression()\n",
        "regr.fit(x_train, y_train)\n",
        "rsquared = regr.score(x_train, y_train)\n",
        "\n",
        "print(f'Training data r-squared: {round(rsquared, 2)}')\n",
        "\n",
        "# Evaluate the coefficients of the model\n",
        "regr_coef = pd.DataFrame(data=regr.coef_, index=x_train.columns, columns=['Coefficient']).round(2)\n",
        "regr_coef.index.name = 'Feature'\n",
        "print(regr_coef)\n",
        "\n",
        "# Calculate the premium for having an extra room\n",
        "premium = regr_coef.loc['RM'].values[0] * 1000\n",
        "print(f'The price premium for having an extra room is ${premium:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3sSyKszdy998"
      },
      "source": [
        "### Analyse the Estimated Values & Regression Residuals\n",
        "\n",
        "The next step is to evaluate our regression. How good our regression is depends not only on the r-squared. It also depends on the **residuals** - the difference between the model's predictions ($\\hat y_i$) and the true values ($y_i$) inside `y_train`.\n",
        "\n",
        "```\n",
        "predicted_values = regr.predict(X_train)\n",
        "residuals = (y_train - predicted_values)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate predicted values and residuals\n",
        "predicted_vals = regr.predict(x_train)\n",
        "residuals = (y_train - predicted_vals)\n",
        "\n",
        "# Original Regression of Actual vs. Predicted Prices\n",
        "plt.figure(dpi=100, figsize=(8, 6))\n",
        "plt.scatter(x=y_train, y=predicted_vals, c='indigo', alpha=0.6)\n",
        "plt.plot(y_train, y_train, color='cyan')\n",
        "plt.title('Actual vs Predicted Prices: $y_i$ vs $\\hat y_i$', fontsize=17)\n",
        "plt.xlabel('Actual prices 000s $y_i$', fontsize=14)\n",
        "plt.ylabel('Predicted prices 000s $\\hat y_i$', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Residuals vs Predicted values\n",
        "plt.figure(dpi=100, figsize=(8, 6))\n",
        "plt.scatter(x=predicted_vals, y=residuals, c='indigo', alpha=0.6)\n",
        "plt.title('Residuals vs Predicted Values', fontsize=17)\n",
        "plt.xlabel('Predicted Prices $\\hat y_i$', fontsize=14)\n",
        "plt.ylabel('Residuals', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Calculate the mean and skewness of the residuals\n",
        "resid_mean = round(residuals.mean(), 2)\n",
        "resid_skew = round(residuals.skew(), 2)\n",
        "\n",
        "# Residual Distribution Chart\n",
        "sns.displot(residuals, kde=True, color='indigo')\n",
        "plt.title(f'Residuals Skew ({resid_skew}) Mean ({resid_mean})')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kC8e42hvdYTd"
      },
      "source": [
        "### Data Transformations for a Better Fit\n",
        "\n",
        "We have two options at this point:\n",
        "\n",
        "1. Change our model entirely. Perhaps a linear model is not appropriate.\n",
        "2. Transform our data to make it fit better with our linear model.\n",
        "\n",
        "Let's try a data transformation approach.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize the original price distribution\n",
        "tgt_skew = data['PRICE'].skew()\n",
        "sns.displot(data['PRICE'], kde='kde', color='green')\n",
        "plt.title(f'Normal Prices. Skew is {tgt_skew:.3}')\n",
        "plt.show()\n",
        "\n",
        "# Perform log transformation on the price data\n",
        "y_log = np.log(data['PRICE'])\n",
        "\n",
        "# Visualize the log price distribution\n",
        "sns.displot(y_log, kde=True)\n",
        "plt.title(f'Log Prices. Skew is {y_log.skew():.3}')\n",
        "plt.show()\n",
        "\n",
        "# Compare the skewness of the original and log price distributions\n",
        "# The distribution with a skew closer to zero is a better candidate for the linear model\n",
        "if abs(y_log.skew()) < abs(tgt_skew):\n",
        "    better_distribution = 'Log Prices'\n",
        "else:\n",
        "    better_distribution = 'Normal Prices'\n",
        "\n",
        "print(f\"The distribution with a skew closer to zero is: {better_distribution}\")\n",
        "\n",
        "# Plot the mapping of original prices to log prices\n",
        "plt.figure(dpi=150)\n",
        "plt.scatter(data.PRICE, np.log(data.PRICE))\n",
        "plt.title('Mapping the Original Price to a Log Price')\n",
        "plt.xlabel('Actual $ Price in thousands')\n",
        "plt.ylabel('Log Price')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6CjqfUD-d4L"
      },
      "source": [
        "## Regression using Log Prices\n",
        "\n",
        "Using log prices instead, our model has changed to:\n",
        "\n",
        "$$ \\log (PR \\hat ICE) = \\theta _0 + \\theta _1 RM + \\theta _2 NOX + \\theta_3 DIS + \\theta _4 CHAS + ... + \\theta _{13} LSTAT $$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split the data into training and test sets using the log prices\n",
        "new_target = np.log(data['PRICE'])  # Use log prices\n",
        "features = data.drop('PRICE', axis=1)\n",
        "\n",
        "X_train, X_test, log_y_train, log_y_test = train_test_split(features, new_target, test_size=0.2, random_state=10)\n",
        "\n",
        "# Perform linear regression using log prices\n",
        "log_regr = LinearRegression()\n",
        "log_regr.fit(X_train, log_y_train)\n",
        "\n",
        "# Calculate the r-squared of the regression on the training data\n",
        "log_rsquared = log_regr.score(X_train, log_y_train)\n",
        "\n",
        "# Make predictions using the log price regression\n",
        "log_predictions = log_regr.predict(X_train)\n",
        "log_residuals = (log_y_train - log_predictions)\n",
        "\n",
        "# Print the r-squared of the regression on the training data\n",
        "print(f'Training data r-squared: {log_rsquared:.2f}')\n",
        "\n",
        "# Determine if the fit of the model has improved compared to before based on the r-squared value\n",
        "if log_rsquared > rsquared:\n",
        "    improvement = 'improved'\n",
        "else:\n",
        "    improvement = 'not improved'\n",
        "\n",
        "print(f'The fit of the model has {improvement} compared to before based on the r-squared value.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8xboGOl-d4P"
      },
      "source": [
        "## Evaluating Coefficients with Log Prices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a DataFrame to store the coefficients of the new regression model\n",
        "df_coef = pd.DataFrame(data=log_regr.coef_, index=X_train.columns, columns=['coef'])\n",
        "\n",
        "# Print out the coefficients of the new regression model\n",
        "print(df_coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "wbRgqfEt-d4e"
      },
      "source": [
        "## Regression with Log Prices & Residual Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scatter plot of Actual vs. Predicted Log Prices\n",
        "plt.scatter(x=log_y_train, y=log_predictions, c='navy', alpha=0.6)\n",
        "plt.plot(log_y_train, log_y_train, color='cyan')\n",
        "plt.title(f'Actual vs Predicted Log Prices: $y_i$ vs $\\hat y_i$ (R-Squared {log_rsquared:.2f})', fontsize=17)\n",
        "plt.xlabel('Actual Log Prices $y_i$', fontsize=14)\n",
        "plt.ylabel('Predicted Log Prices $\\hat y_i$', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot of Original Actual vs. Predicted Prices\n",
        "plt.scatter(x=y_train, y=predicted_vals, c='indigo', alpha=0.6)\n",
        "plt.plot(y_train, y_train, color='cyan')\n",
        "plt.title(f'Original Actual vs Predicted Prices: $y_i$ vs $\\hat y_i$ (R-Squared {rsquared:.3f})', fontsize=17)\n",
        "plt.xlabel('Actual prices 000s $y_i$', fontsize=14)\n",
        "plt.ylabel('Predicted prices 000s $\\hat y_i$', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot of Residuals vs. Predicted values (Log prices)\n",
        "plt.scatter(x=log_predictions, y=log_residuals, c='navy', alpha=0.6)\n",
        "plt.title('Residuals vs Fitted Values for Log Prices', fontsize=17)\n",
        "plt.xlabel('Predicted Log Prices $\\hat y_i$', fontsize=14)\n",
        "plt.ylabel('Residuals', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot of Residuals vs. Predicted values\n",
        "plt.scatter(x=predicted_vals, y=residuals, c='indigo', alpha=0.6)\n",
        "plt.title('Original Residuals vs Fitted Values', fontsize=17)\n",
        "plt.xlabel('Predicted Prices $\\hat y_i$', fontsize=14)\n",
        "plt.ylabel('Residuals', fontsize=14)\n",
        "plt.show()\n",
        "\n",
        "# Calculate the mean and skew for the residuals using log prices\n",
        "log_resid_mean = round(log_residuals.mean(), 2)\n",
        "log_resid_skew = round(log_residuals.skew(), 2)\n",
        "\n",
        "# Plot the distribution of residuals using log prices\n",
        "sns.displot(log_residuals, kde=True, color='navy')\n",
        "plt.title(f'Log price model: Residuals Skew ({log_resid_skew}) Mean ({log_resid_mean})')\n",
        "plt.show()\n",
        "\n",
        "# Plot the distribution of residuals in the original model\n",
        "sns.displot(residuals, kde=True, color='indigo')\n",
        "plt.title(f'Original model: Residuals Skew ({resid_skew}) Mean ({resid_mean})')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfbvfrJmfmiR"
      },
      "source": [
        "# Compare Out of Sample Performance\n",
        "\n",
        "The *real* test is how our model performs on data that it has not \"seen\" yet. This is where our `X_test` comes in."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otZnpoaD-VIw",
        "outputId": "c17395c0-6a18-4b71-d153-aac26cf46143"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Model Test Data r-squared: 0.67\n",
            "Log Model Test Data r-squared: 0.74\n"
          ]
        }
      ],
      "source": [
        "# Calculate and print the r-squared for the original model on the test dataset\n",
        "original_model_r2 = regr.score(X_test, y_test)\n",
        "print(f'Original Model Test Data r-squared: {original_model_r2:.2f}')\n",
        "\n",
        "# Calculate and print the r-squared for the log model on the test dataset\n",
        "log_model_r2 = log_regr.score(X_test, log_y_test)\n",
        "print(f'Log Model Test Data r-squared: {log_model_r2:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb5Dxrmq41lt"
      },
      "source": [
        "# Predict a Property's Value using the Regression Coefficients\n",
        "\n",
        "Our preferred model now has an equation that looks like this:\n",
        "\n",
        "$$ \\log (PR \\hat ICE) = \\theta _0 + \\theta _1 RM + \\theta _2 NOX + \\theta_3 DIS + \\theta _4 CHAS + ... + \\theta _{13} LSTAT $$\n",
        "\n",
        "The average property has the mean value for all its charactistics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The log price estimate is $3.030\n",
            "The property is estimated to be worth $20703.18\n",
            "The log price estimate is $3.250\n",
            "The property is estimated to be worth $25792.03\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average values of the features\n",
        "average_vals = features.mean().values\n",
        "\n",
        "# Create a DataFrame with the average values as a single row\n",
        "property_stats = pd.DataFrame(data=average_vals.reshape(1, len(features.columns)), columns=features.columns)\n",
        "\n",
        "# Predict the value of the average property using the stats above\n",
        "log_estimate = log_regr.predict(property_stats)[0]\n",
        "print(f'The log price estimate is ${log_estimate:.3f}')\n",
        "\n",
        "# Convert Log Prices to Actual Dollar Values\n",
        "dollar_est = np.exp(log_estimate) * 1000\n",
        "print(f'The property is estimated to be worth ${dollar_est:.2f}')\n",
        "\n",
        "# Define Property Characteristics\n",
        "next_to_river = True\n",
        "nr_rooms = 8\n",
        "students_per_classroom = 20 \n",
        "distance_to_town = 5\n",
        "pollution = data.NOX.quantile(q=0.75)  # high\n",
        "amount_of_poverty =  data.LSTAT.quantile(q=0.25)  # low\n",
        "\n",
        "# Set Property Characteristics in the property_stats DataFrame\n",
        "property_stats['RM'] = nr_rooms\n",
        "property_stats['PTRATIO'] = students_per_classroom\n",
        "property_stats['DIS'] = distance_to_town\n",
        "\n",
        "if next_to_river:\n",
        "    property_stats['CHAS'] = 1\n",
        "else:\n",
        "    property_stats['CHAS'] = 0\n",
        "\n",
        "property_stats['NOX'] = pollution\n",
        "property_stats['LSTAT'] = amount_of_poverty\n",
        "\n",
        "# Make prediction for the property with specified characteristics\n",
        "log_estimate = log_regr.predict(property_stats)[0]\n",
        "print(f'The log price estimate is ${log_estimate:.3f}')\n",
        "\n",
        "# Convert Log Prices to Actual Dollar Values\n",
        "dollar_est = np.exp(log_estimate) * 1000\n",
        "print(f'The property is estimated to be worth ${dollar_est:.2f}')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
